{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,signal, copy\n",
    "import math\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import pickle\n",
    "import numpy as np                                       # fast vectors and matrices\n",
    "import matplotlib.pyplot as plt                          # plotting\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal.windows import hann\n",
    "\n",
    "import musicnetRaven as musicnet\n",
    "\n",
    "from time import time\n",
    "\n",
    "sys.path.insert(0,'lib/')\n",
    "import config\n",
    "import diagnosticsP3\n",
    "# import base_model\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'   # see issue #152\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3'\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import conv1d, mse_loss\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "from tqdm import tqdm\n",
    "import mir_eval\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for returning scientific notation in a plot\n",
    "def fmt(x, pos):\n",
    "    a, b = '{:.0e}'.format(x).split('e')\n",
    "    b = int(b)\n",
    "    return fr'${a} \\times 10^{{{b}}}$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lvl1 convolutions are shared between regions\n",
    "m = 128\n",
    "k = 500              # lvl1 nodes\n",
    "n_fft = 4096              # lvl1 receptive field\n",
    "window = 16384 # total number of audio samples?\n",
    "stride = 512\n",
    "batch_size = 500\n",
    "regions = 1 + (window - n_fft)//stride\n",
    "\n",
    "def worker_init(args):\n",
    "    signal.signal(signal.SIGINT, signal.SIG_IGN) # ignore signals so parent can handle them\n",
    "    np.random.seed(os.getpid() ^ int(time())) # approximately random seed for workers\n",
    "kwargs = {'num_workers': 15, 'pin_memory': True, 'worker_init_fn': worker_init}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used =  30.10122060775757\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "root = '../data/'\n",
    "train_set = musicnet.MusicNet(root=root, epoch_size=100000\n",
    "                              , train=True, download=True, refresh_cache=False, \n",
    "                              window=window, mmap=False)#, pitch_shift=5, jitter=.1)\n",
    "test_set = musicnet.MusicNet(root=root, train=False, download=True, refresh_cache=False, window=window, epoch_size=50000, mmap=False)\n",
    "print(\"Time used = \", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_size,**kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_size,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filters(n_fft, freq_bins=None, low=50,high=6000, mode=\"fft\"):\n",
    "    if freq_bins==None:\n",
    "        freq_bins = n_fft//2+1\n",
    "    \n",
    "    s = np.arange(0, n_fft, 1)\n",
    "    wsin = np.empty((freq_bins,1,n_fft), dtype=np.float32)\n",
    "    wcos = np.empty((freq_bins,1,n_fft), dtype=np.float32)\n",
    "    start_freq = low\n",
    "    end_freq = high\n",
    "    # num_cycles = start_freq*d/44000.\n",
    "    # scaling_ind = np.log(end_freq/start_freq)/k\n",
    "    \n",
    "    if mode==\"fft\":\n",
    "        window_mask = 1\n",
    "    elif mode==\"stft\":\n",
    "        window_mask = hann(n_fft, sym=False) # same as 0.5-0.5*np.cos(2*np.pi*x/(k))\n",
    "    else:\n",
    "        raise Exception(\"Unknown mode, please chooes either \\\"stft\\\" or \\\"fft\\\"\")\n",
    "        \n",
    "\n",
    "    for k in range(freq_bins): # Only half of the bins contain useful info\n",
    "        wsin[k,0,:] = window_mask*np.sin(2*np.pi*k*s/n_fft)\n",
    "        wcos[k,0,:] = window_mask*np.cos(2*np.pi*k*s/n_fft)\n",
    "    \n",
    "    return wsin,wcos\n",
    "\n",
    "def create_filtersv2(n_fft, freq_bins=None, low=50,high=6000, mode=\"fft\"):\n",
    "    if freq_bins==None:\n",
    "        freq_bins = n_fft//2+1\n",
    "    \n",
    "    s = torch.arange(0, n_fft, 1.)\n",
    "    wsin = torch.empty((freq_bins,1,n_fft))\n",
    "    wcos = torch.empty((freq_bins,1,n_fft))\n",
    "    start_freq = low\n",
    "    end_freq = high\n",
    "    # num_cycles = start_freq*d/44000.\n",
    "    # scaling_ind = np.log(end_freq/start_freq)/k\n",
    "    \n",
    "    if mode==\"fft\":\n",
    "        window_mask = 1\n",
    "    elif mode==\"stft\":\n",
    "        window_mask = 0.5-0.5*torch.cos(2*math.pi*s/(n_fft)) # same as hann(n_fft, sym=False)\n",
    "    else:\n",
    "        raise Exception(\"Unknown mode, please chooes either \\\"stft\\\" or \\\"fft\\\"\")\n",
    "        \n",
    "\n",
    "    for k in range(freq_bins): # Only half of the bins contain useful info\n",
    "        wsin[k,0,:] = window_mask*torch.sin(2*math.pi*k*s/n_fft)\n",
    "        wcos[k,0,:] = window_mask*torch.cos(2*math.pi*k*s/n_fft)\n",
    "    \n",
    "    return wsin,wcos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = torch.nn.MSELoss()\n",
    "def L(yhatvar,y):\n",
    "    return Loss(yhatvar,y) * 128/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, avg=.9998):\n",
    "        super(Model, self).__init__()\n",
    "        # Create filter windows\n",
    "        wsin, wcos = create_filtersv2(n_fft,k, mode=\"stft\")\n",
    "        with torch.cuda.device(0):\n",
    "            self.wsin = torch.Tensor(wsin).cuda()\n",
    "            self.wcos = torch.Tensor(wcos).cuda()\n",
    "            \n",
    "        # Creating Layers\n",
    "        self.linear = torch.nn.Linear(regions*k, m)\n",
    "        torch.nn.init.constant_(self.linear.weight, 0) # initialize\n",
    "        \n",
    "        self.avg = avg\n",
    "        #Create a container for weight average\n",
    "        self.averages = copy.deepcopy(list(parm.cuda().data for parm in self.parameters())) \n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        zx = conv1d(x[:,None,:], self.wsin, stride=stride).pow(2) \\\n",
    "           + conv1d(x[:,None,:], self.wcos, stride=stride).pow(2)\n",
    "        return self.linear(torch.log(zx + 10e-8).view(x.data.size()[0],regions*k))\n",
    "    \n",
    "    def average_iterates(self):\n",
    "        for parm, pavg in zip(self.parameters(), self.averages):\n",
    "            pavg.mul_(self.avg).add_(1.-self.avg, parm.data) # 0.9W_avg + 0.1W_this_ite\n",
    "    \n",
    "    \n",
    "@contextmanager\n",
    "def averages(model):\n",
    "    orig_parms = copy.deepcopy(list(parm.data for parm in model.parameters()))\n",
    "    for parm, pavg in zip(model.parameters(), model.averages):\n",
    "        parm.data.copy_(pavg)\n",
    "    yield\n",
    "    for parm, orig in zip(model.parameters(), orig_parms):\n",
    "        parm.data.copy_(orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaged Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\ttrain loss\ttest loss\ttrain avg\ttest avg\ttime\tutime\n",
      "0\t1.069328\t1.103995\t0.466764\t0.344857\t17.4\t6.0\n",
      "1\t0.926604\t1.075843\t0.605397\t0.520665\t17.0\t5.9\n",
      "2\t0.904341\t1.041473\t0.623976\t0.561042\t16.9\t5.9\n",
      "3\t0.894038\t1.016879\t0.631741\t0.586639\t17.1\t6.0\n",
      "4\t0.888097\t0.992118\t0.640120\t0.600159\t18.0\t6.7\n",
      "5\t0.881837\t0.962664\t0.642732\t0.608177\t19.0\t6.8\n",
      "6\t0.881854\t0.939733\t0.647524\t0.614123\t18.7\t6.1\n",
      "7\t0.878364\t0.915281\t0.648318\t0.619560\t19.2\t6.7\n",
      "8\t0.878097\t0.900461\t0.650981\t0.624896\t18.8\t6.6\n",
      "9\t0.875794\t0.879261\t0.652495\t0.628364\t18.8\t6.6\n",
      "10\t0.875469\t0.864928\t0.655083\t0.633904\t19.1\t6.8\n",
      "11\t0.872329\t0.852620\t0.656504\t0.631492\t18.8\t6.7\n",
      "12\t0.868874\t0.833082\t0.657461\t0.633796\t19.1\t6.4\n",
      "13\t0.870437\t0.816059\t0.659410\t0.637046\t19.1\t6.6\n",
      "14\t0.865245\t0.804317\t0.658679\t0.636859\t19.1\t6.6\n",
      "15\t0.867316\t0.797100\t0.659559\t0.640901\t18.5\t6.5\n",
      "199/200 batches\r"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.cuda()\n",
    "loss_history_train = []\n",
    "avgp_history_train = []\n",
    "loss_history_test = []\n",
    "avgp_history_test = []\n",
    "epochs = 20\n",
    "avg = .9998\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6, momentum=.95)\n",
    "# optimizer = SWA(base_opt, swa_start=0, swa_freq=1, swa_lr=0.000001)\n",
    "\n",
    "try:\n",
    "    with train_set, test_set:\n",
    "        total_i = len(train_loader)\n",
    "        print(\"epoch\\ttrain loss\\ttest loss\\ttrain avg\\ttest avg\\ttime\\tutime\")\n",
    "        for e in range(epochs):\n",
    "            yground = torch.FloatTensor(batch_size*len(train_loader), m) # what not do this together with loss\n",
    "            yhat = torch.FloatTensor(batch_size*len(train_loader), m)\n",
    "            avgp, loss_e = 0.,0\n",
    "            t = time()\n",
    "            for i, (x,y) in enumerate(train_loader):\n",
    "                print(f\"{i}/{total_i} batches\", end = '\\r')\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # making x and y into pytorch dealable format\n",
    "                x = x.cuda(non_blocking=True)\n",
    "                y = y.cuda(non_blocking=True)\n",
    "                yhatvar = model(x)\n",
    "                loss = L(yhatvar,y)\n",
    "                loss.backward()\n",
    "                loss_e += loss.item() #getting the number\n",
    "                \n",
    "                yground[i*batch_size:(i+1)*batch_size] = y.data\n",
    "                yhat[i*batch_size:(i+1)*batch_size] = yhatvar.data\n",
    "                \n",
    "                optimizer.step()\n",
    "                model.average_iterates() # Averaging the weights for validation\n",
    "                \n",
    "            avgp = average_precision_score(yground.flatten(),yhat.flatten())    \n",
    "            loss_history_train.append(loss_e/len(train_loader))\n",
    "            avgp_history_train.append(avgp)   \n",
    "            t1 = time()\n",
    "            avgp, loss_e = 0.,0.           \n",
    "#             optimizer.swap_swa_sgd() # change to average weight\n",
    "            \n",
    "            # For testing\n",
    "            yground = torch.FloatTensor(batch_size*len(test_loader), m) # what not do this together with loss\n",
    "            yhat = torch.FloatTensor(batch_size*len(test_loader), m)\n",
    "            \n",
    "            with averages(model):\n",
    "                for i, (x_test,y_test) in enumerate(test_loader):\n",
    "                    x_test = x_test.cuda()\n",
    "                    y_test = y_test.cuda()\n",
    "                    yhatvar = model(x_test)\n",
    "                    loss_e += L(yhatvar, y_test).item() #getting the number\n",
    "\n",
    "                    yground[i*batch_size:(i+1)*batch_size] = y_test.data\n",
    "                    yhat[i*batch_size:(i+1)*batch_size] = yhatvar.data\n",
    "                avgp = average_precision_score(yground.cpu().flatten(),yhat.cpu().flatten())\n",
    "                loss_history_test.append(loss_e/len(test_loader))\n",
    "                avgp_history_test.append(avgp)\n",
    "                print('{}\\t{:2f}\\t{:2f}\\t{:2f}\\t{:2f}\\t{:2.1f}\\t{:2.1f}'.\\\n",
    "                      format(e,\n",
    "                             loss_history_train[-1],loss_history_test[-1],\n",
    "                             avgp_history_train[-1],avgp_history_test[-1],\n",
    "                             time()-t, time()-t1))\n",
    "\n",
    "\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('Graceful Exit')\n",
    "else:\n",
    "    print(\"Finsihed\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(loss_history_train)\n",
    "plt.plot(loss_history_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f685f9685f8>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avgp_history_train)\n",
    "plt.plot(avgp_history_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Mirex stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mir_accuracy(Yhatpred, Y_true):\n",
    "    Yhatlist = []\n",
    "    Ylist = []\n",
    "\n",
    "    for i in range(len(Yhatpred)):\n",
    "        print(f\"{i}/{len(Yhatpred)} batches\", end = '\\r')\n",
    "        fhat = []\n",
    "        f = []\n",
    "        for note in range(m):\n",
    "            if Yhatpred[i][note] == 1:\n",
    "                fhat.append(440.*2**(((note)-69.)/12.))\n",
    "\n",
    "            if Y_true[i][note] == 1:\n",
    "                f.append(440.*2**(((note)-69.)/12.))\n",
    "\n",
    "        Yhatlist.append(np.array(fhat))\n",
    "        Ylist.append(np.array(f))\n",
    "    avp = average_precision_score(Y_true.flatten(),Yhatpred.detach().cpu().flatten())\n",
    "    P,R,Acc,Esub,Emiss,Efa,Etot,cP,cR,cAcc,cEsub,cEmiss,cEfa,cEtot = \\\n",
    "    mir_eval.multipitch.metrics(np.arange(len(Ylist))/100.,Ylist,np.arange(len(Yhatlist))/100.,Yhatlist)\n",
    "    print('{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}'.format(100*avp,100*P,100*R,Acc,Etot,Esub,Emiss,Efa))\n",
    "    return avp,P,R,Acc,Etot\n",
    "def get_piano_roll(rec_id, window=16384, stride=1000, offset=44100, count=7500):\n",
    "    sf=4\n",
    "    if stride == -1:\n",
    "        stride = (test_set.records[rec_id][1] - offset - int(sf*window))/(count-1)\n",
    "        stride = int(stride)\n",
    "    else:\n",
    "        count = (test_set.records[rec_id][1] - offset - int(sf*window))/stride + 1\n",
    "        count = int(count)\n",
    "        \n",
    "    X = np.zeros([count, window])\n",
    "    Y = np.zeros([count, m])    \n",
    "        \n",
    "    for i in range(count):\n",
    "        X[i,:], Y[i] =  test_set.access(rec_id, offset+i*stride)\n",
    "        \n",
    "    X = torch.tensor(X).float().cuda()\n",
    "    Y_pred = model(X)\n",
    "    \n",
    "    return Y_pred, Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2556, 2303, 2382, 2416, 2191, 2298, 2106, 2628, 1819, 1759]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.rec_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "19.98\t82.63\t22.04\t0.21\t0.79\t0.03\t0.75\t0.01\n",
      "26.07\t76.57\t32.37\t0.29\t0.70\t0.08\t0.60\t0.02\n",
      "4.67\t52.81\t6.00\t0.06\t0.96\t0.03\t0.91\t0.02\n",
      "25.88\t59.61\t41.94\t0.33\t0.79\t0.08\t0.50\t0.21\n",
      "5970/7500 batches\r"
     ]
    }
   ],
   "source": [
    "print('AvgP\\tP\\tR\\tAcc\\tETot\\tESub\\tEmiss\\tEfa')\n",
    "\n",
    "for songid in test_set.rec_ids:\n",
    "    Y_pred, Y_true = get_piano_roll(songid, stride=-1)\n",
    "    Yhatpred = Y_pred > 0.4\n",
    "    get_mir_accuracy(Yhatpred, Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
